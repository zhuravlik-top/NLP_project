Задача: классификации текстов по предметным областям.

Цель:
Предсказать предметный класс текста: Физика, Химия или Биология.


1.EDA 

Описание данных:

Датасет содержит 8695 текстов с тремя категориями: Biology (3591), Chemistry (2920), Physics (2184).

Каждая запись содержит поля: Id, Comment (текст), Topic (метка).

Дубликаты: встречается 745 полных повторов текстов, часть из которых имеют разные метки (20 конфликтных случаев).

Анализ текста:

Длины текстов сильно различаются: от 1 до 7298 символов, средняя длина ~169 символов.

Количество слов в тексте: от 1 до 1274, среднее ~27 слов.

Было решено фильтровать тексты с количеством слов меньше 10 для улучшения качества обучения. После фильтрации осталось 5435 текстов.

После очистки текстов и приведения к нижнему регистру дубликатов с противоречивыми метками не осталось.

Распределение слов:

Для каждой категории рассмотрено распределение длины текстов (слов). Большинство текстов в каждой категории имеют меньше 100 слов.

Были рассмотрены часто встречающиеся слова в каждой группе, что помогает понять ключевые термины:

Biology: n, like, would, one, get, people, think, know, cells, water

Physics: n, would, time, like, energy, physics, think, one, light, force

Chemistry: n, like, would, get, chemistry, one, make, water, acid, use

Примененные преобразования:

Тексты очищены от лишних символов, приведены к нижнему регистру.

Разделение данных на тренировочную, валидационную и тестовую выборки:

Train: 3804 текста

Validation: 815 текста

Test: 816 текста

Выводы EDA:

Баланс классов неплохой, но Physics немного меньше.

Фильтрация коротких текстов помогает убрать шумные данные.

Очистка текста и токенизация необходимы для последующего обучения моделей.

Частотный анализ слов помогает понять тематические особенности классов.


2.BASELINE

Постановка базовой модели:
Для проверки качества классификации текстов были использованы несколько базовых моделей(использовались как варианты с очищенным текстом так и без):

DummyClassifier (стратегия most_frequent).

LogisticRegression (с liblinear и max_iter=1000).

LinearSVC — линейный SVM для многоклассовой классификации.

DecisionTreeClassifier (глубина 4).

RandomForestClassifier — ансамбль деревьев решений.

CatBoostClassifier — градиентный бустинг с деревьями решений.

Препроцессинг текста:

Для моделей использовался CountVectorizer с биграммами (ngram_range=(1,2)), min_df=3, max_df=0.9.

Отбирались 5000 лучших токенов через SelectKBest с метрикой chi2, чтобы убрать слишком частые или неинформативные слова(пробовалось разное количество токенов, лучший результат при использовании 5000).

Также проверялась версия с TfidfVectorizer и аналогичной селекцией признаков.

Разделение данных:

Тренировочная выборка: 3804 текста

Валидационная выборка: 815 текста

Тестовая выборка: 816 текста

Результаты:

Контрольная модель DummyClassifier имеет F1, Precision и Accuracy близкие к 0, что подтверждает сбалансированность задачи.

Лучшие результаты показали LinearSVC и LogisticRegression с F1 в диапазоне ~0.7–0.74 на 5-кратной кросс-валидации.

Снижение числа признаков до 1000 (SelectKBest) дало небольшое улучшение для LinearSVC (+0.011 F1), но ухудшило результат для других моделей.

Использование TfidfVectorizer вместо CountVectorizer дало небольшой прирост для SVM (~+0.057 F1) и незначительные изменения для других моделей.

Выводы baseline:

Линейные модели (SVM, Logistic Regression) работают лучше на текстах с TF/TF-IDF признаками.

Снижение числа признаков может быть полезно для уменьшения вычислительной нагрузки, но влияет на качество модели по-разному для разных алгоритмов.

Бустинговые методы (CatBoost, RandomForest) без дополнительной настройки показали чуть худшие результаты, но их можно улучшить тюнингом гиперпараметров.


3.IMPROVEMENTS:

Цель

После построения базовых моделей (Logistic Regression, SVM, Random Forest, CatBoost) проведены эксперименты по улучшению качества классификации текстов по предметным областям. Ниже описаны использованные архитектуры, преобразования и их влияние на итоговые метрики.




Глубокие модели

CNN (1D сверточная сеть)

Архитектура:

Embedding (30k токенов, размерность 128)

Conv1D (256 фильтров, ядро 5)

GlobalMaxPooling

Dropout (0.5)

Dense (3 класса, softmax)

Результаты:

Валидация F1_macro = 0.749

Тест F1_macro = 0.776

Пояснение: CNN улавливает локальные паттерны и сочетания слов (n-граммы), что хорошо подходит для коротких предложений, но не учитывает дальние зависимости.




BiLSTM + Attention

Архитектура:

Embedding (30k токенов, размерность 128)

Bidirectional LSTM (64 нейрона)

Attention слой (взвешивает значимость слов в контексте)

Dropout (0.5)

Dense (3 класса, softmax)

Результаты:

Валидация F1_macro = 0.773

Тест F1_macro = 0.794

Прирост: +0.02–0.03 по сравнению с CNN.

Пояснение: BiLSTM захватывает контекст в обе стороны, а Attention усиливает вклад ключевых слов (например, “reaction”, “force”, “cell”), что особенно полезно для предметной классификации.
Модель показала хороший баланс между качеством и вычислительными затратами.




SentenceTransformer (all-MiniLM-L6-v2) + Logistic Regression / SVM

Суть: Использованы sentence-эмбеддинги размерности 384, затем обучались линейные классификаторы.

Результаты:

Валидация F1_macro = 0.764

Тест F1_macro = 0.812

Прирост: +0.07–0.08 F1_macro к лучшему baseline.

Пояснение: Контекстные эмбеддинги MiniLM позволяют различать значения терминов в разных предметах (например, “bond” в физике и химии).





DistilBERT

Суть: Использована distilbert-base-uncased, дообученная на задаче классификации (3 класса) с AdamW и scheduler.

Результаты:

Валидация F1_macro = 0.797

Тест F1_macro = 0.806

Прирост: +0.07 относительно baseline.

Пояснение: Трансформер эффективно обрабатывает контекст целого предложения, но требует больше ресурсов; при этом на относительно небольшом датасете (≈5k текстов) прирост ограничен.



Сводное сравнение моделей


Logistic Regression	TF-IDF	~0.72	~0.73	—	Базовая модель

LinearSVC	TF-IDF	~0.74	~0.74	+0.02	Лучший baseline

CNN	Embedding + Conv1D	0.75	0.78	+0.04	Локальные закономерности

BiLSTM + Attention	Embedding + контекст	0.77	0.79	+0.05	Учет контекста и важности слов

SentenceTransformer + LogReg	Эмбеддинги (MiniLM)	0.76	0.81	+0.07	Контекстные вектора

DistilBERT (fine-tuning)	Трансформер	0.80	0.81	+0.07	Максимальное качество

 Общие выводы

BiLSTM + Attention дал стабильный прирост по сравнению с CNN, показав лучшее качество среди собственных нейросетей без предобученных эмбеддингов.

SentenceTransformer и DistilBERT обеспечили наибольшие метрики, демонстрируя преимущество контекстных эмбеддингов.

TF-IDF остаётся эффективным и лёгким базовым методом.

Бустинговые модели (CatBoost, RandomForest) без тонкой настройки уступили нейросетевым и контекстным подходам.
